I have 3 years of experience in pl/sql and i work around besal support, batch monitoring and DQ checks and we configured T2T's 
here my roles & responsibilities are when ever the batch is failing, we check the batch monitoring and we fix the batch issue and any new enhancement comming
and guide lines comming we use to implement that new changes and then we change code level, what ever the chages we do in UAT Environment and after that one
we execute the batches and genarate the RCA3 reports,and we share those RCA3 reports and exposer level reports to the Bank,they will check that report,
if every thing is fine as per them like expected numbers every thing is comming then they will provide the sign-off after that one, we will release code to
production through CR(Change request) they deploy the CR, along with that one we done some optimization of batch also initially it is use to execute  60 to 70
Hours, after that one we have done optimization, on top of Optimization each rules optimiation we have done by adding some proper hints,indexes we have added.

sequence of batch is initially we get the data from the bank source system to prestage area, once the data is loded into the prestage, ETL team will do 
some transformations and after that one they will lode the data into ofssa staging tables, once the data is avilable in ofssa staging table, we internally,
we will do some transformations like what ever the data is comming from the tables.
				                                                                      Here we have 2 types of tables 
				                                                                            	|- pp(product processor) tables 
				                                                                            	|- non-pp tables 

All pp tables comming from ETL & all non-pp tables are comming from initial uplode and then once the data is available and then internally we do some trasformations 
and then we lode the data into our internal staging tables  like  stage exposer, master, party master, rating master like that, once that is avilable we will run
SED(slowly changing dimention), so here SED's are 3 parts
						                                      |- type1,2,3 SED's
Type-1 SED: genarally till not maintain the history, it will override the data what ever the data it is commimg, it will maintain only one record for one to one type of records. Where as
Type-2 SED: it will maintain the history of previous record also in the dimention table, that will maintain the history based on the latest indicator plan along with that
            record start data date. like that we execute the SED's, we can see the SED's types & these things in 2 tables
						                                                                                                  	|- sys_tbl_master
						                                                                                                  	|- sys_stg_join_master

 
In sys_stg_join_master we can see the what type of SED's and what are the columns we are useing for the SED's. that is the SED's
once the SED's are completed, then we will run the DQ checks(Data Quality), suppose any pp table data is there referencial data we check properly like date condition,
any product code like anything is missing then that records will comming as a failure records. once the DQ checks are completed then DQ reports are Downloded by the banks,
and then they verify the data, and then any currection is required they do the currections, if at all the data currection is not required they just sed go a head further,
and then we can run the main Capital calculation(Basel Capital calculation) batch will be start. in this perticular batch we have that Rules, T2T's, Data Transformation & 
these things, in this batch we actually caluculate the RWC(Risk Weighted caluculations) all these things we do, initially we lode the data from stageing to non packet exposer 
predictories and after that we do the recaptiliation of product type, party type assect class clasification all these things, once it is done we will apply the credit ratings,
and apply the risk weight based on the different different conditions, like based on the accet class, credit rating, party type on all these things we apply the ratings and
then finally we calculated the risk weighted  Accet. after that the data will flow into the rect table(regulatory tables),once the data lode into rect tables on top of the 
rect table some metirialized views are there those things will be refresh and then the report will be genarated on top of mertilied views.





Table Names
------------
 Fct_non_sec_exposures
 Fct_sec_exposures
 Fct_market_risk_exposures
 Dim_basel_credit_rating
 Dim_product
 Dim_basel_credit_rating
 Fct_common_account_summary
 Stg_loan_contracts
 Stg_td_contracts
 Stg_investment
 Stg_futures
 Stg_swaps
 Stg_forwards
 Stg_options  
 Fct_mitignats
 Fct_sub_exposures
