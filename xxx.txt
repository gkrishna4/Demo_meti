 Docker demen process:- https://chatgpt.com/share/dec866e9-7d83-425d-bc75-595da0122823
jenkins shared libraries :- https://chatgpt.com/share/6415334f-b4ca-4511-aeba-93307161c8b1
how we can execute the microservices for that how we need to write the jenkins file:-           https://chatgpt.com/share/29edcfc0-3cf5-4e2a-bb9d-a0d8c60a8a18
we have multiple stages in the Jenkins pipeline, How we can build single stage and how we can skip remaining:-    https://chatgpt.com/share/39060863-61b6-4587-be5c-786510d86ca9

How to check whether the syntax of a shell script is correct without executing it?
==================================================================================
The bash -n command is used to check the syntax of a script without executing it.
bash -n script.sh
sh -n script.sh
ksh -n script.sh

Maven Life cycle?
=================
> compile:---- compiles the source code
> test:------ Runs Unit Tests
> package:----- creates JAR/WAR/EAR
> install:---- installs artifact to local repo
> deploy:----- deployes the artifact to remote Repo

How Many ways you can trigger the Build?
===========================================
we can trigger the Build in 3 ways
1) pollSCM
2) Web hook
3) Build piriadically

 How to add a new worker node in Jenkins ?
=========================================
 Log into the Jenkins master and navigate to Manage Jenkins > Manage Nodes > New Node. Enter a name for the new node and select Permanent Agent.
Configure SSH and click on Launch.

How to add a new plugin in Jenkins ?
=====================================
Using the CLI, java -jar jenkins-cli.jar install-plugin <PLUGIN_NAME>

Using the UI,
-------------
Click on the "Manage Jenkins" link in the left-side menu.
Click on the "Manage Plugins" link.

 What is JNLP and why is it used in Jenkins ?
==============================================
In Jenkins, JNLP is used to allow agents (also known as "slave nodes") to be launched and managed remotely by the Jenkins master instance. This allows Jenkins to
distribute build tasks to multiple agents, providing scalability and improving performance.
When a Jenkins agent is launched using JNLP, it connects to the Jenkins master and receives build tasks, which it then executes.
The results of the build are then sent back to the master and displayed in the Jenkins user interface.



Difference between Continuous Delivery & Continuous Deployment
================================================================
Continuous Delivery:-   A process where code changes are automatically built, tested, and prepared for release (The code is always ready to be deployed, but the actual
deployment to production is done manually. so here the code is always in a deployable state and reduces the risk of issues.)

Continuous Deployment- 	A process where code changes are automatically built, tested, and deployed to production.( Every change that passes the tests is automatically 
deployed to production without any manual steps.Speeds up the delivery of new features and fixes to users)

what are the Release types using in Your Organization?
======================================================
MAJOR: 3 to 6 months                    [ here Major and Minor came into the Feature Devlopment]
MINOR: 2 weeks to 3 months
HOTFIX: 1 day to 2 weeks (BugFix)

major.minor.hotfix.BuildNo
----  ----  -----  -------
  x  . x   .  x   .  x

for example we can see the QA/Release Build
------------------------------------------------
when ever the release is sheduled, here the release manger is going to coardinate with all the teams to release the project

here all the teams sence 

--> Requirement analysis
--> design
--> Devlopment
--> testing 
--> Production

he is the persion monitor wether the release is going smooth /not
and he will maintain the Release-calander.

Release manager will prepare XL sheet it will defind Who needs to do what & when, he is the persoin will shedule the tasks

QA Builds == 10    [will sheduled execute every monday & thrusday]  

Performance Builds == 5 [wensday]

UAT Builds == 2  [will sheduled & execute  every 1.5 month and 1.5 month] tuesday

what is continuous intigration
==============================
Let's say we have multiple devlopers working on the same application, each of them have their own feature (or) bug-fix that they are 
working-on and they all are contributing the same application, by pushing their code into the same code repository like GitHub. when the 
devloper pushes the code to the repository it will link to a build mangement system like jenkins, that takes the code and build's it, 
so here multiple devlopers pushing their code to the same application, we would like to make shore it build currectly & it will not 
intraduce new issues into the application for this we can configure the build system to run testcases on  build package. once the 
testcase's pass successfull, we can conform that the build cycle complete this whole process we call it as continuous intigration


how to maintain the end to end software devlopment and what are the tools using there?
=======================================================================================
when ever devloper commited the feature branch, performing few stages like cloning, compileing 
and then performing the unit testing and sonarQube analasis and all, so once these stages are completed 
then the notification will get the devloper, if the changes are good and we can mearge the changes into the
dev environment, by creating the PR(pull request). but here we have a the break down its not continuous becouse some manual
approvals are required before moving to the UAT Pre-prod

How do I copy a job from one jenkins instance to another?
==========================================================
1)Export the Job from the Source Jenkins Instance:
	Go to the Jenkins dashboard on your source instance.
	Navigate to the job you want to copy.
	Click on the job to open its configuration page.
	On the left-hand menu, click on "Configure".
	Scroll to the bottom and click on the "Pipeline Syntax" link (for pipeline jobs) or look for "Job Configuration" options.
	Click on the "View as XML" link. This will display the jobâ€™s configuration in XML format.
	Save this XML file to your local system.

2)Import the Job to the Target Jenkins Instance:
	Go to the Jenkins dashboard on your target instance.
	Click on "New Item".
	Enter a name for the new job.
	Select "Freestyle project" (or other relevant job type) and click "OK".
	Instead of configuring the job from scratch, click on the "Configure" link.
	At the bottom of the configuration page, look for an "Advanced Project Options" section and find the "Use custom workspace" option.
	Instead of filling out the fields manually, look for an option to upload the XML configuration file (you may need to use a plugin like "Job Import Plugin" for this step).
	Upload the XML file you saved earlier.
	Save the configuration.


what is the default path of the jenkins?
========================================
the default  path of the jenkins is for ubuntu: /home/ubuntu/.jenkins/jobs/project-Name/workspace/target/webapps/java-web-app.war

the default  path of the jenkins is for RHEL/CentOS: /home/ec2-user/.jenkins/jobs/project-Name/workspace/target/webapps/java-web-app.war

/var/lib/jenkins/jobs/project-Name/workspace/target/webapps/java-web-app.war

the path where we can store the war/ear files in the tomcat server?
===================================================================
/usr/local/tomcat/webapps/java-web-app.war

what are the Advantage of Jenkins?
==================================
Bugs tracking are easy at early stage in development environment.
Provides a large numbers of plugin support.
Iterative improvement to the code.
Build failures are cached at integration stage.
For each code commit changes an automatic build report notification generates.
To notify developers about build report success or failure, it is integrated with LDAP mail server.
Achieves continuous integration agile development and test driven development.
With simple steps, maven release project is automated.

What is Jenkinsfile?
=====================
The text file where all the definitions of pipelines are defined is called Jenkinsfile. It is being checked in the source control repository

 (or)

A Jenkinsfile is like a recipe for Jenkins,  Just like a recipe tells you how to cook a meal step by step,
Like that Jenkinsfile tells to Jenkins, how to build, test, and deploy your software step by step.

Instead of clicking buttons in the Jenkins web interface to set up your build process, you write code in a Jenkinsfile. 
This code describes what Jenkins should do when it's building your software. It includes things like:

1)Getting the source code from a repository (like GitHub).
2)Building the code.
3)Running tests to make sure everything works.
4)Packaging the software.
5)Deploying it to servers or other places.

By putting this process into code, you can version-control it along with your actual software code. This means changes to your
build process can be tracked, reviewed, and reverted just like changes to your software.

Note:-  A Jenkinsfile is a way to define your software build process as code, making it easier to automate and manage with Jenkins
------

what are the ways to install the jenkins?
==========================================
jenkins can be install by using:-
1)package mangers like apt, yum , brew(mac).
2)Docker (docker images for jenkins is avilable for different platforms  like unix/mac/windows in the docker registry)
3)kubernets (availble as a helm chart and can be installed on our kubernets cluster)

How to create a backup and copy files in Jenkins?
=================================================
Backup data is crucial to any business, If you have right backupâ€™s & in case of any recovery needed to tackle with 
any unexpected situations like , datacenter outage , Jenkins system failures or accidental deletion of data. 

There are multiple method to backup the Jenkins configuration such as

    using ThinBackup or Backup plugin
    using the git repo
    manually backing up the Jenkins configuration or schedule a shell script using the cron. 

The easiest approach which I found is to use the Jenkins plugin for the backup.
click on manage jenkins----->manage plugins----> Available-->here search for thinbackup plugin & install without restart
thenafter in manage jenkins there we can find the ThinBackUp click on that and configure the settigs 
there we can give the folder where we can store the jenkins backup, cronJobs for when u take the backup, and how many backups we can store...etc
then after we can Backup and restore the data. 

explain the pipeline?
=====================
A pipeline is a set of automated processes and tools that allows both developers
and operations teams to work together, to build and deploy code to a production environment. 
to build, continuous integration, automation testing, validation, and reporting. 
It may also include one or more manual gates that require human intervention before code is allowed to proceed.

This includes continuous integration, continuous delivery/deployment (CI/CD), continuous feedback, 
and continuous operations. Instead of one-off tests or scheduled deployments, each function occurs on an ongoing basis.

how do u migrate the jenkins? without downtime?
==============================================
Jenkins jobs can be migrated in many ways. You can establish SSH connection b/w source machine and target machine and use scp
command to copy from one instance to another instance. You can also use Job import plug-in to migrate jobs.

https://www.coachdevops.com/2020/06/migrate-jenkins-jobs-from-one-server-to.html


what are the chalenges you fased in devops?
===========================================
running pipeline in jenkins, depending on the worklode, secodary node is came to the pitcher,
if lot of teams are deploying changes or checking the code at the same time. So it is vary slow to scale.
Because primary node has the fixed size,and upgrade it to bigger size required manuvally
or it takes some time even if want to do automated way 

hard to troubleshoot because there are so many jenkins plugins, if the team just adopted the new plugin
they have to get use to how the plugin does error report & all

i sloved it, by using code pipeline for newer projects, codepipeline scales automatically,it doesnt use any ec2
or any server, it is serverless so it is payas u go.  by using lamda we can check metriks in cloud watch.

 what is lamda?
================
lamda is for automation purpose for the daily metrics, for supose we have one usecase is there like ENI triggers 
only so where ever the ec2 instance created, here some triggering will be happend after that instances are
created.
so most of the time application team can't take care that one, so for that, we did a small automation so if we
update one metric in the cloud watch & cloud trail. if any log is genarated, create an instance then automatically
cloud watch metic will be copied.

inside that we have lamda function and it featched the instance details and based on that it will created a tag
like application name,account_id etc based on featching.
so based on that it will create the tag and it will attached to that line
and lamda function will be written in python botto-3 for that manage.

what are the tools u are used in the unit testing?
====================================================
junit is there and jecaco plugin we install to move the test casess and we integrate those  repororts to
 the sonarQube,to see the covarage and everything in the SonarQube dashbord to understand more

what is SonarQube Qubality gate?
=================================
Here by default sonarQube has one qulaity-gate, which is going to apply for all our projects/jobs for a perticular job we want to use
use custome quality gate, and that to if our requirement is code covarage <=80, need to mark it as a failed, for that perpose
we can use the Quality gate
for that in the sonarQube server clickon--->Qualitygates---->create--->gave the name.
then after we have an opction in the right-side called ----> Add-condition
and it will promt one popup, there we can select an opction called covarage there we can give the covarge.
    
 What is sonarQube Quality Profile
====================================
Here we are going to specify the set of rules which are going to use during the analysis of your source code,
based of your language, we need to set the rules so that when ever sonarqube is analysing your project, using those roles
it is going to give the feedback to the devlopers & also it will identify any buges/issues with the code

here by default, for for each language it is going to create a default profile called as sonar-way.
when we click on the sonar-way we can see that, what are the different rules which are defaind for those perticular profile.

why u are using the sonarQube/How does SonarQube detect code smells, bugs, and vulnerabilities?
==============================
SonarQube detects code smells, bugs, and vulnerabilities through static code analysis. 
SonarQube checks for common code smells like duplicated code, overly complex methods, or poor naming conventions.
scans the programming mistakes that can lead to errors or unexpected behavior. identifies security weaknesses in the code,
It checks for issues like SQL injection, cross-site scripting (XSS), or improper authentication.

how to change the default port number 9000 to custum port in sonarQube?
========================================================================
go to the conf directory and open the sonar.properties and search for

sonar.web.port=9000 and replace

how to execute the sonarQube Report for maven projects?
=======================================================
mvn clean install sonar:sonar


if we don't mention the sonarqube server details in the pom.xml,we can use the bellow commands
mvn clean sonar:sonar package -Dsonar.host.url=http://localhost:9000

          (or)
mvn clean package sonar:sonar -Dsonar.host.url=http://localhost:9000
Dsonar.login=admin -Dsonar.password=admin

           (or)
mvn clean package sonar:sonar -Dsonar.host.url=http://localhost:9000
Dsonar.login=token

how to maintain the password encripted in jenkins?
==================================================
in the jenkins dashbord,we can find manage jenkins in the left pannel click on that, under this we can find  
credentials section there we have to create the username and password, and token for bitbucket
we have use token, performing the deployments and all, for this we have system accounts directly we use those credentials 
where required, per-suppose connect the nexus repository, for that we have Binded the username and password
just we use that token when we did that step.

if u have to design a system infra for 200 user, so how do u design?
===================================================================
per supose the system have the 200 users means, that system shoud have the more capacity like 
cpu & memory wise, even the file system should be manage like one,  profile created to every user
so some default storage used at /home, it should have more memory & all, even credentials we have to
 manage for that


i have one DataBase and one UI, we have a application server and we have a database server,with out down the
system how we can deploy the aplication into the server?
=============================================================================================================
here we have a two situvation like one approuch is like stoping the service & doing the updations and all
but the another thing is like, to create the same configuration in another machine, there we have done all the 
sanity testing & delivery. Once it's fine just we switching the traffic to new one


========================================================================================================



what is Docker?
--------------

Docker implements a high-level API to provide lightweight containers that run processes in isolation.
A Docker container enables rapid deployment with minimum run-time requirements. It also ensures better
management and simplified portability.



How we can move/copy images from one server to another server without repo?
---------------------------------------------------------------------------

	In source server(where we have image)
	Save image(All the layers) as a tar file by using the command
                                               docker save -o <filename>.tar <ImageName/ID> 
	Then scp the tar-file from Source to Destination server
	And in destination server we can run
                                      docker lode -i <FileName>.tar 



Suppose your server has 10GB ram, so while creating the container set the limit as 200mb, 
what will happen if lot of lode on that particular application?
------------------------------------------------------------------------------------------------
Incase of memory the container will be stopped, but incase of CPU it will not stop, performance will be vary slow,
because the speed of our process depends on number of CPUâ€™s  

sudo docker run -it --memory="<memory_limit>"  <docker_image>

For example, if you set --memory to 1 GB, as in the example above, the amount of swap memory needs to be more than that.
To run a container with an additional 1 GB of swap memory, set the swap memory to 2 GB.

The syntax for running a container with limited memory and additional swap memory is:
----------------------------------------------------------------------------------------
sudo docker run -it --memory="<memory_limit>" --memory-swap="<memory_limit>" <docker_image>


Set Soft Limit to Container Memory
------------------------------------
As an example, for an Ubuntu container to have the memory reservation of 750 MB and the maximum RAM capacity of 1 gb, use the command:

sudo docker run -it --memory="1g" --memory-reservation="750m" ubuntu



What is the difference between docker run & create?
----------------------------------------------------
docker create will only create a container but it will not start the container
docker run will create a container & start the container  


What is shell form & executable form in docker?
-----------------------------------------------
RUN/CMD/ENTRYPOINT instructions/commands can be defind in shell form (or) executable form.

In Docker, "shell form" and "executable form" refer to two different ways of specifying the command 
that should be executed when a container is started.
Shell Form:
==========
In shell form, the command is specified as a single string with the command and its arguments separated by spaces.
For example:
--------------
CMD echo "Hello, world!"
In this case, the command echo "Hello, world!" is executed using the default shell (/bin/sh) of the container.

Executable Form:
===================
In executable form, the command is specified as an array of strings,
where the first element is the executable and subsequent elements are its arguments.
For example:
---------------
CMD ["echo", "Hello, world!"]
In this case, the command echo "Hello, world!" is executed directly without invoking a shell.
This form is preferred when the command does not require shell-specific features like variable expansion or redirection.

Both forms can be used with the CMD instruction in a Dockerfile to specify the default command to run when a container starts. 
The choice between shell form and executable form depends on the requirements of the command being executed and whether
shell-specific features are needed.

What is the difference between CMD & RUN?
---------------------------------------
Run instructions will be execute while creating a image.CMD instructions will be executed while 
Creating a container. we can have more than one RUN keyword in a docker-file. All RUN keywordâ€™s
Will be processed while creating an image in the defind order (Top to Bottom).


What is the difference between CMD & ENTRYPOINT?
-------------------------------------------------
CMD commands/instructions can be overridden while creating a container. 
ENTRYPOINT commands/instructions cannot be overridden while creating a container. 


Suppose we have the following Dockerfile:

Dockerfile
------------
FROM ubuntu
CMD echo "Hello, world!"

In this Dockerfile, the CMD instruction specifies that the default command to run when the container starts is echo "Hello, world!".

Now, let's build and run the container:
docker build -t my_container .
docker run my_container
When we run the container without providing any additional arguments, it will execute the default command
specified in the Dockerfile, which is echo "Hello, world!". So, the output will be:
Hello, world!

Now, let's say we want to override the default command and execute a different command when running the container.
We can do this by providing the desired command as an argument to docker run. For example:

docker run my_container echo "Goodbye, world!"

In this case, we are overriding the default command specified in the Dockerfile (echo "Hello, world!")
with a new command (echo "Goodbye, world!"). So, the output will be:

Goodbye, world!
This demonstrates how CMD can be overridden by providing arguments to docker run.


How do you do the os patches  in the docker swarm/worker machines with out impact your applications/Containers?
----------------------------------------------------------------------------------------------------------------
We can drain the machine so that container will move to another machine and we can do performance like whatever
 the activity You want to do, then again we make it active.
 
to drain the node
--------------------
docker node update --availability drain <NODE-ID>

# Apply OS patches and updates
apt update && apt upgrade

# Reboot if required
reboot

to make active
--------------
docker node update --availability active <NODE-ID>

Repeat the above steps for each node in the Docker Swarm, updating them 
one by one to minimize the impact on your applications.

cache busting 
------------------ 
Whenever an image is build from a dockerfile, docker reads its memory and checks which instructions were already 
executed. These steps will not be Re-executed. 
It will execute only the latest instructions. This is a time saving mechanism provided by docker. But, the disadvantage is, 
we can end up installing software packages from a repository which is updated long time back. 

TO avoid this disadvanatge we use cache busting 
------------------------------------------------------------------- 
Note: cache busting is implemented using && symbol. 
each statement in the docker file has && will be re-executed. 



Container orchestration 
------------------------ 
Running docker containers in a distributed environment, on multiple docker host machines. 
All these containers can have a single service running on them and they share the resources between eachother,
even running on different host machines. 
 
Docker swarm is the tool used for performing container orchestration 
 
Advantages 
-------------- 
1) Load balancing 
2) scaling of containers 
3) performing rolling updates 
4) handling failover scenarios

how can we reuse the yml files in ansible?
==============================================
there are 3 ways to do this: includes, imports & roles

includes and imports allow users to breakup large playbooks into smaller files, which can be 
used accross multiple parent playbooks (or) even multiple times with in the same playbook

roles allow more then just tasks to be packaged together and can include the variables, handlers, or even modules and plugins
unlike includes and imports roles can also be updated and shared via ansible galaxy


what is the difference between NACL & security group?
=====================================================
we can use NACL, subnet level to protect the subnets &
security group can be protected for EC2 instances 


what is the difference between web-server & Application server?
===============================================================  refer====> https://www.youtube.com/watch?v=BcmUOmvl1N8
web server can provide the support for only for web related technologies like html, css, javaScript,servlets...etc.
webservers can not able to handel backend related code & aslo we can used for lodeBalancing

Example of Web Servers:
-----------------------
Apache Tomcat
Ngnix
IBM Http server

Application servers used for deploying the backend code(java code), and Application servers can able to
process your bussiness logic. Here inside every application server, inbuilt webserver will be present to 
provide support for web-related technologies 

Examples of Application Server:
---------------------------------
                    vendor
                    ------
Weblogic----------->Oracle
JBoss/wildfly------>redhat-------> redhat now aquired by IBM
Websphere---------->IBM


JBoss/Wildfly is the enterprize application servers, we can deploy EAR & WAR files
but in tomcat we can deploy only WAR files. that's  why we can call tomcat is a web-application server

What is the diff between JAR, WAR and EAR?
========================================== Refer====>https://www.youtube.com/watch?v=ecxIBCu2-b4
>> JAR(java Archive):it contains a group of .class files 
>> WAR file contains a web application
>> EAR file containes the enterprize application

JAR file have Java class files, associated metadata and resources aggregated into a single file to execute a Java application.
  executable jar file:
                        JDK provides the facility to create the executable jar file. 
			An executable jar file calls the main method of the class if you double click it.
                        To create the executable jar file, you need to create .mf file.              (mf means manifest file.)
WAR file that contain Servlet, JSP, HTML, JavaScript and other files necessary for developing web applications.
        allows testing and deploying web applications easily 
EAR file allows deploying different modules onto an application server simultaneously

What is a POM XML file why it is used?
=======================================
POM.XML is mavenâ€™s main configuration file where we keep all details related to project. It contains
â€¢ Metadata about that project
â€¢ Dependencies required to build the project
â€¢ The kind of project
â€¢ Kind of output you want (.jar, .war)
â€¢ Description about that project 



for example my tomcat server is not running how you debug?
===========================================================
go to the logs folder there we can find one file called--->catalina.out
and check catalina.out


you have devloped your application & you are going to deploy now. once u deploy the application where it will store?
====================================================================================================================
in webapps

all the deployed application's are avilable in the webapps


why we need to use repositories such as nexus or Docker hub, since we have already Git /Bitbucket/svn?
=======================================================================================================
Git/Bitbucket/svn is a source referential for version control (with features like merging, branching, tags)

Nexus/Docker-Hub is an artifact referential for any delivery.
simply a collection of shared directories with a naming convention ( group.artifact.version ).


what is devops kpi?
====================
1)Deployment Frequency
2)Deployment Time/Speed
3)Deployment Failure Rate
4)MTTR (Mean Time to Recover)

Refer====>  https://www.clickittech.com/devops/devops-metrics-and-kpis/

DevOps Best Pratices  Refer===>  https://www.clickittech.com/devops/devops-best-practices/#container-orchestration

what is the life-cycle of DevOps? 
==================================
DevOps lifecycle consists of several stages, each contributing to the development, deployment, and improvement of software
products. Here's a simplified breakdown:

Plan:
Define project goals, requirements, and timelines.
Activities include defining user stories and estimating resources.

Code:
Developers write and commit code changes to version control systems like Git.
Collaboration among team members is crucial for writing clean, efficient code.

Build:
Code is compiled, tested, and packaged into deployable artifacts.
Automation tools like Jenkins automate the build process for consistency and reliability.

Test:
Various testing techniques ensure software functionality, performance, and security.
Unit tests, integration tests, and security scans are common practices.

Deploy:
Software artifacts are deployed to different environments (e.g., development, staging, production) using automation tools like 
Ansible or Kubernetes.
Automation reduces manual errors and deployment time.

Operate:
The software is monitored, maintained, and optimized for performance and reliability.
Monitoring tools track application health and performance metrics in real-time.

Monitor:
Continuous monitoring and feedback loops track application performance and usage.
Metrics and logs are analyzed to identify areas for improvement.

Iterate:
Teams iterate on the software based on monitoring feedback and user input.
Continuous integration and delivery pipelines facilitate rapid releases for quick adaptation to market demands.
In summary, the DevOps lifecycle emphasizes collaboration, automation, and continuous improvement to efficiently deliver 
high-quality software and adapt to changing market needs.

how can we remove the installed packages with configuration files?
============================================================
sudo apt-get --purge remove <package-name>


in tomcat server where we can update/add the users
===================================================
go to the ===> cd /etc/tomcat8/
here we can find the file==> tomcat-users.xml
under this we can we can add the users
EX:-
     <user username="learning" password="sunilsunil" roles="manager-script,manager-status,manager-gui"/>


How we can change the port number of a tomcat server
=====================================================
Go to the conf directory and open the server.xml there we can modify
<Container port="8080" 
     protocal="HTTP/1.1"
     connectionTimeout="2000"
     redirectPort="8443"/>
here we can replace the 8080 with any port number


suppose in a perticular server there are two applications are running the same port number? how can you find it?
or
how do we check the open port in linux?
===================================================================================================================
we can check 3 ways by making use the commands

1) netstat -ltnp | grep -w :<port number>

l â€“ tells netstat to only show listening sockets.
t â€“ tells it to display tcp connections.
n â€“ instructs it to show numerical addresses.
p â€“ enables showing of the process ID and the process name.
grep -w â€“ shows matching of exact string (:80).


2)$ lsof -i :<port number>
           (or)
sudo lsof -i -P -n | grep LISTEN

3)$ ps -p <process-id> -o comm= 


How to write a script to delete messages in a log file older than 30 days automatically?

find <Path_To_Old_Files> -type f -mtime +30 -delete (Example)
find /opt/backup -type f -mtime +30 -delete (For under /opt/backup 
directory)
find /var/log -name "*.log" -type f -mtime +30 -delete (For files 
matching the criteria)




